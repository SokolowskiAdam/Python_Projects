{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example input table\n",
    "import pandas as pd\n",
    "input_table_1 = pd.DataFrame({\"Example\": [\"Example\"]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if 2 files are the same using their checksum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"     \n",
    "Script which was used to check if workflow which loads files to database is loading the same file. \n",
    "It checks checksum of the new file which is going to be loaded to the database with previous one. \n",
    "If checksum is the same it means that the file which should be loaded to the database is the same as the previous one,\n",
    "which is already in the database, therefore it shouldnt be loaded.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import hashlib\n",
    "\n",
    "# Copy input to output -> KNIME Python node \n",
    "# input_table_1 - table passed in the workflow to the Python node (KNIME)\n",
    "output_table_1 = input_table_1.copy()\n",
    "\n",
    "# Saving paths from table to variables\n",
    "file_path_recent = input_table_1.loc[0, 'local_full_path_recent']\n",
    "file_path_previous = input_table_1.loc[0, 'local_full_path_previous']\n",
    "path_list = [file_path_recent, file_path_previous]\n",
    "\n",
    "checksum_list = []\n",
    "# Getting checksum for every file from the list\n",
    "for path in path_list:\n",
    "    with open(path, \"rb\") as f:\n",
    "        data = f.read()\n",
    "        md5 = hashlib.md5(data).hexdigest()  # md5 algorithm, output returned in hexadecimal digits\n",
    "        checksum_list.append(md5)\n",
    "\n",
    "df_checksum_check = pd.DataFrame({\"Path\": path_list, \"Checksum\": checksum_list})\n",
    "checksum_check = [df_checksum_check[\"Checksum\"][0] != df_checksum_check[\"Checksum\"][1]]\n",
    "\n",
    "# Output needed to be returned in DataFrame -> script was used in Knime which is based on tabular data\n",
    "output_table_1 = pd.DataFrame({\"Different_checksum\": checksum_check})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text encoding conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Script used for correction of broken encoding of german letters in manufacturer's names.\n",
    "Correction from windows-1250 encoding to standard utf-8\n",
    "Data was taken from excel file with list of broken names of manufacturers\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "excel_path = \"\"\n",
    "cnx = \"Database connection\"\n",
    "\n",
    "df_german_1250 = pd.read_excel(excel_path, sheet_name=\"german encoding\")\n",
    "\n",
    "# Correction of broken encoding of manufacturers names - from windows-1250 to utf-8\n",
    "df_german_1250['name_in_utf8'] = df_german_1250.apply(lambda x: x['name'].encode(\"windows-1250\", errors='ignore').decode('utf-8'), axis=1)\n",
    "\n",
    "list_of_german_manuf = df_german_1250['name_in_utf8'].to_list()\n",
    "list_of_german_manuf_query = \", \".join(\"'\" + str(x).upper() + \"'\" for x in list_of_german_manuf)  # german manufacturers list for sql query\n",
    "\n",
    "man_query = f\"\"\" select id,\n",
    "                name,\n",
    "                full_name\n",
    "                from postgres_database.manufacturer\n",
    "                where upper(full_name) in ({list_of_german_manuf_query})\n",
    "\"\"\"\n",
    "df_manufacturers_ger = pd.read_sql_query(man_query, cnx)\n",
    "\n",
    "df_german_1250['name_in_utf8_upper'] = df_german_1250['name_in_utf8'].apply(lambda x: x.upper())\n",
    "df_manufacturers_ger['full_name_upper'] = df_manufacturers_ger['full_name'].apply(lambda x: x.upper())\n",
    "\n",
    "df_ger_man_final = pd.merge(df_german_1250, df_manufacturers_ger, left_on='name_in_utf8_upper', right_on='full_name_upper', how='left')\n",
    "\n",
    "# Test string showing how decoding works in following script\n",
    "test_broken_decoding_ger = \"DĂ–RR\"\n",
    "print(test_broken_decoding_ger.encode(\"windows-1250\").decode('utf-8'))\n",
    "\n",
    "# Appending DataFrame with result to excel file\n",
    "with pd.ExcelWriter(excel_path, engine=\"openpyxl\", mode=\"a\") as writer:\n",
    "    df_ger_man_final.to_excel(writer, index=False, sheet_name='german_check')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Price check in loaded file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Script used to check price in file which is going to be loaded to the database.\n",
    "It checks if price in currently loaded file is higher/lower than max/min price for product.\n",
    "Max/min price for each product is counted in different workflow and stored in database.\n",
    "If price of product in currently loaded file is 30% higher/lower than max/min price,\n",
    "such product is suspicious. If 30% of prices in file are \"suspicious\" it means that following\n",
    "file should not be loaded and that it should be checked manually.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Copy input to output -> KNIME Python node \n",
    "# input_table_1 - table passed in the workflow to the Python node (KNIME)\n",
    "output_table_1 = input_table_1.copy()\n",
    "\n",
    "# If input table is empty it means that table with max/min price for products does not have information for following data source\n",
    "# Therefore checked file cannot be compared with max/min price table -> it receives status: pass\n",
    "\n",
    "def suspicious_prices_check(input_table_1: pd.DataFrame) -> pd.DataFrame:\n",
    "    if input_table_1.empty:\n",
    "        return pd.DataFrame({'file_passed_price': [True],\n",
    "                            'percentage_of_suspicious_products': [0],\n",
    "                            'number_of_suspicious_products': [0],\n",
    "                            'number_of_all_products': [0]})\n",
    "    else:\n",
    "        input_table_1['smaller'] = input_table_1.apply(lambda x: True if x['price_in_pln'] < x['min_price'] - (x['min_price'] * 0.3) else False, axis=1)\n",
    "        input_table_1['higher'] = input_table_1.apply(lambda x: True if x['price_in_pln'] > x['max_price'] + (x['max_price'] * 0.3) else False, axis=1)\n",
    "        input_table_1['pass'] = input_table_1.apply(lambda x: True if x['smaller'] == False and x['higher'] == False else False, axis=1)\n",
    "\n",
    "        df_grouped_pass = input_table_1[['product_id', 'pass']].groupby('pass').count().reset_index().sort_values(by='pass')\n",
    "        \n",
    "        # Protection from no True or False statuses generated\n",
    "        df_empty_table = pd.DataFrame({'pass': [True, False], 'product_id': [0,0]})\n",
    "        \n",
    "        df_grouped_pass = pd.concat([df_grouped_pass, df_empty_table])\n",
    "        df_grouped_pass = df_grouped_pass[['pass', 'product_id']].groupby('pass').sum().reset_index()\n",
    "\n",
    "        false_qty = int(df_grouped_pass[(df_grouped_pass['pass'] == False)]['product_id'].to_string(index=False))\n",
    "        number_of_prices = input_table_1.shape[0]\n",
    "        \n",
    "        # Check if ratio of false (suspicious) quantites is lower than 30%\n",
    "        passed = false_qty / number_of_prices * 100 < 30\n",
    "        false_percent = round(false_qty / number_of_prices * 100, 2)\n",
    "\n",
    "        return pd.DataFrame({'file_passed_price': [passed],\n",
    "                            'percentage_of_suspicious_products': [false_percent],\n",
    "                            'number_of_suspicious_products': [false_qty],\n",
    "                            'number_of_all_products': [number_of_prices]})\n",
    "\n",
    "output_table_1 = suspicious_prices_check(input_table_1)      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File size checker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Simple script which checks if recently loaded file is bigger/smaller/the same as previously loaded file.\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "\n",
    "# Copy input to output -> KNIME Python node \n",
    "# input_table_1 - table passed in the workflow to the Python node (KNIME)\n",
    "output_table_1 = input_table_1.copy()\n",
    "\n",
    "recent_file_size = int(input_table_1['local_file_size_recent'][0])\n",
    "previous_file_size = int(input_table_1['local_file_size_previous'][0])\n",
    "source_type = input_table_1['source_type'].to_string(index=False)\n",
    "\n",
    "\n",
    "def file_size_checker(recent_file_size: int, previous_file_size:int, source_type: str) -> pd.DataFrame:    \n",
    "    # Different percentage ratio for inhouse suppliers/manufacturers\n",
    "    if source_type in (\"Inhouse supplier\", \"Inhouse manufacturer\"):\n",
    "        percentage = 0.2\n",
    "    else:\n",
    "        percentage = 0.4\n",
    "\n",
    "    if recent_file_size > previous_file_size + (previous_file_size * percentage):\n",
    "        file_pass = False\n",
    "        reason = \"File bigger than previous one\"\n",
    "    elif recent_file_size < previous_file_size - (previous_file_size * percentage):\n",
    "        file_pass = False\n",
    "        reason = \"File smaller than previous one\"\n",
    "    elif recent_file_size == previous_file_size:\n",
    "        file_pass = False\n",
    "        reason = \"File size is the same as previous one\"\n",
    "    else:\n",
    "        file_pass = True\n",
    "        reason = \"File is ok\"\n",
    "        \n",
    "    file_percentage = round(recent_file_size / previous_file_size * 100, 2)\n",
    "    \n",
    "    return pd.DataFrame({\"file_passed_size\": [file_pass],\n",
    "                         \"size_check_reason\": [reason],\n",
    "                         'recent_file_size': [recent_file_size],\n",
    "                         'previous_file_size': [previous_file_size],\n",
    "                         'percentage_recent_to_previous': [file_percentage]})\n",
    "\n",
    "output_table_1 = file_size_checker(recent_file_size, previous_file_size, source_type)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
