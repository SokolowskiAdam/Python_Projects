{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "remove_input",
     "remove_output"
    ]
   },
   "source": [
    "# Source Validation - report\n",
    "\n",
    "Idea of following report is to show user the most important information about the quality of data source. Each data source constist sales data taken from daughter companies. Script was created to check if data source can be migrated to production instance. Result of following report is saved in html file, which should be checked by the person who has created it and rated if everything with the source is ok.\n",
    "\n",
    "Technical info:\n",
    "- Report is based on Python and SQL queries\n",
    "- Final result is displayed in section Final report, apart of raw data there are also plots which help to visualise/find anomalies and suspicious data\n",
    "- Result of the report is html file, which is created in last cell -> it is based on jupyter notebook cell tags\n",
    "- Every cell has its tag which suggest what should be done with it in html file:\n",
    "    - remove_input - code input is not saved to html file\n",
    "    - remove_output - output of cell is not saved to html file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove_input"
    ]
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import sqlalchemy\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source ID + database connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove_input"
    ]
   },
   "outputs": [],
   "source": [
    "# ID of the source\n",
    "while True:\n",
    "    try:\n",
    "        SOURCE_ID = int(input(\"Insert SOURCE_ID which should be checked: \").strip())\n",
    "    except ValueError:\n",
    "        print(\"Please insert a number\")\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# Login data \n",
    "database_username = input(\"Please insert database LOGIN: \").lower().strip()\n",
    "database_password = input(\"Please insert database PASSWORD: \")\n",
    "\n",
    "# Float format display - 3 decimal places\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove_input"
    ]
   },
   "outputs": [],
   "source": [
    "# DB credentials\n",
    "POSTGRES_ADDRESS = '111.11.11.11' ## DB ADDRESS IF IT'S NOT ON PANOPLY\n",
    "POSTGRES_PORT = '5555'\n",
    "POSTGRES_USERNAME = f'{database_username}' ## PANOPLY/POSTGRES USERNAME\n",
    "POSTGRES_PASSWORD = f'{database_password}' ## PANOPLY/POSTGRES PASSWORD \n",
    "POSTGRES_DBNAME = 'postgres_database' ## DATABASE NAME\n",
    "\n",
    "# A long string that contains the necessary Postgres login information\n",
    "postgres_str = ('postgresql://{username}:{password}@{ipaddress}:{port}/{dbname}'.format(username=POSTGRES_USERNAME,\n",
    "                                                                                        password=POSTGRES_PASSWORD,\n",
    "                                                                                        ipaddress=POSTGRES_ADDRESS,\n",
    "                                                                                        port=POSTGRES_PORT,\n",
    "                                                                                        dbname=POSTGRES_DBNAME))\n",
    "\n",
    "# Create the connection\n",
    "cnx = sqlalchemy.create_engine(postgres_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove_input"
    ]
   },
   "outputs": [],
   "source": [
    "# Source name\n",
    "source_details = f\"\"\"select name\n",
    "                        from postgres_database.source_details\n",
    "                        where id = {SOURCE_ID}\n",
    "                        \"\"\"\n",
    "\n",
    "try:\n",
    "    df_source_name = pd.read_sql(source_details, cnx)\n",
    "except Exception as e:\n",
    "        print(str(e))\n",
    "        \n",
    "SOURCE_NAME = df_source_name.full_name.to_string(index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove_input",
     "remove_output"
    ]
   },
   "outputs": [],
   "source": [
    "# First and last source loading\n",
    "\n",
    "SOURCE_LOAD_DATETIME = f\"\"\" select sl.source_id\n",
    "                            , max(sl.load_datetime)  as max_load_datetime_source_loading_info\n",
    "                            , min(sl.load_datetime)  as min_load_datetime_source_loading_info\n",
    "                            , max(sli.load_datetime) as max_load_datetime_source_loading_info_init\n",
    "                            , min(sli.load_datetime) as min_load_datetime_source_loading_info_init\n",
    "                        from postgres_database.source_loading_info sl\n",
    "                                join postgres_database.source_loading_info_init sli\n",
    "                                    on sl.id = sli.source_loading_info_id\n",
    "                        where sl.source_id = {SOURCE_ID}\n",
    "                        and sl.load_datetime >= '2022-01-01'::date\n",
    "                        group by 1 \"\"\"\n",
    "                                \n",
    "try:\n",
    "    df_source_load_datetime = pd.read_sql_query(SOURCE_LOAD_DATETIME, cnx)\n",
    "    \n",
    "except Exception as e:\n",
    "        print(str(e))\n",
    "\n",
    "# Source loading dates - min i max\n",
    "SOURCE_LOAD_DATE_MIN = df_source_load_datetime['min_load_datetime_source_loading_info'].to_string(index=False)[:10]\n",
    "SOURCE_LOAD_DATE_MAX = df_source_load_datetime['max_load_datetime_source_loading_info'].to_string(index=False)[:10]\n",
    "\n",
    "print(f\"First load date: {SOURCE_LOAD_DATE_MIN}\")\n",
    "print(f\"Last load date: {SOURCE_LOAD_DATE_MAX}\")\n",
    "\n",
    "# Dates which are going to be used in a loop for downloading the data from the database\n",
    "SOURCE_LOAD_DATE_MIN_MINUS_1_DAY = (df_source_load_datetime['min_load_datetime_source_loading_info'] + pd.DateOffset(-1)).to_string(index=False)[:10]\n",
    "SOURCE_LOAD_DATE_MAX_PLUS_1_DAY = (df_source_load_datetime['max_load_datetime_source_loading_info'] + pd.DateOffset(1)).to_string(index=False)[:10]\n",
    "\n",
    "# Time periods for downloading the data\n",
    "load_dates_intervals = pd.date_range(SOURCE_LOAD_DATE_MIN_MINUS_1_DAY, SOURCE_LOAD_DATE_MAX_PLUS_1_DAY, periods=6, inclusive='both')\n",
    "\n",
    "# Date conversion for SQL query\n",
    "load_dates_intervals_str = [str(date.to_period('D')) for date in load_dates_intervals]\n",
    "load_dates_intervals_str_string = ', '.join(load_dates_intervals_str)\n",
    "print(load_dates_intervals_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove_input"
    ]
   },
   "outputs": [],
   "source": [
    "# Looking for suspicious source loads\n",
    "try:\n",
    "    querry = f\"\"\"select\n",
    "                    load_datetime,\n",
    "                    load_reason,\n",
    "                    purpose,\n",
    "                    coalesce(branch,'null') as branch, \n",
    "                    coalesce(workflow_name,'null') as \"workflow_name\",\n",
    "                    coalesce(row_count,0) as row_count,\n",
    "                    source_id,\n",
    "                    datetime_added,\n",
    "                    coalesce(manufacturer_column,'null') as manufacturer_column,\n",
    "                    coalesce(prod_name_col,'null') as prod_name_col,\n",
    "                    load_datetime as \"weeks\"\n",
    "                from postgres_database.source_loading_info_init\n",
    "                where source_id = {SOURCE_ID} and load_datetime >= '{SOURCE_LOAD_DATE_MIN}'::date\n",
    "                order by load_datetime asc;\"\"\"\n",
    "                \n",
    "    df_row_count = pd.read_sql(querry, cnx)\n",
    "    \n",
    "except Exception as e:\n",
    "        print(str(e))\n",
    "\n",
    "df_row_count['load_datetime'] = pd.to_datetime(df_row_count['load_datetime'], utc=True)\n",
    "manufacturer_column = df_row_count[[\"manufacturer_column\", \"load_datetime\"]].groupby([\"manufacturer_column\"]).agg(['min', 'max', 'count'])\n",
    "prod_name_col = df_row_count[[\"prod_name_col\", \"load_datetime\"]].groupby([\"prod_name_col\"]).agg(['min', 'max', 'count'])\n",
    "df_row_count.rename(columns = {'row_count': 'amount'}, inplace = True)\n",
    "df_row_count2 = df_row_count[['weeks','amount','load_datetime','workflow_name']].groupby(['weeks','workflow_name']).agg({'amount':'sum','load_datetime':'first'}).sort_values(by='load_datetime').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove_input"
    ]
   },
   "outputs": [],
   "source": [
    "# Function to detect all suspicious values if exist + calculate statistics\n",
    "def suspicious_data(dataframe):\n",
    "    df = pd.DataFrame(dataframe[0:0])\n",
    "    median = dataframe.amount.median()\n",
    "    std = dataframe.amount.std()\n",
    "    minim = dataframe.amount.min()\n",
    "    maxim = dataframe.amount.max()\n",
    "    \n",
    "    suspected_row_counts = []\n",
    "    for i in dataframe.amount:\n",
    "        if i < median - 2 * std or i > median + 2 * std:\n",
    "            suspected_row_counts.append(i)\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    suspected_row_counts.sort()\n",
    "    \n",
    "    if len(suspected_row_counts) == 0:\n",
    "        print(f\"No suspicious data was found in source files from all {dataframe.count().max()} rows\")\n",
    "    else:\n",
    "        print(f\"Suspicious data was found in source files {len(suspected_row_counts)} times \\nfrom all {max(dataframe.count())} rows \\nThey take the following values: \")        \n",
    "    \n",
    "    print(f\"\"\"\n",
    "\n",
    "    Maximum value:\n",
    "    {maxim}\n",
    "\n",
    "    Average value:\n",
    "    {median}\n",
    "\n",
    "    Minimum value:\n",
    "    {minim}\n",
    "    \n",
    "    Standard deviation:\n",
    "    {std}\n",
    "    \"\"\")\n",
    "\n",
    "    if len(suspected_row_counts) > 0:\n",
    "        print(f\"\"\"Following values are suspicious: {suspected_row_counts}\"\"\")\n",
    "    elif len(suspected_row_counts) == 0:\n",
    "        print(\"\"\"No suspicious values were found\"\"\")\n",
    "    else:\n",
    "        print(\"\"\"Following values needs to be checked\"\"\")\n",
    "    \n",
    "    df = dataframe[(dataframe['amount'].isin(suspected_row_counts))] \n",
    "    pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)  # Display whole DataFrame\n",
    "    \n",
    "    return display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove_input"
    ]
   },
   "outputs": [],
   "source": [
    "#Loads per date from postgres_database.source_loading_info\n",
    "try:\n",
    "    querry = f\"\"\"\n",
    "                select \n",
    "                count(*) as amount,\n",
    "                load_datetime::timestamp,\n",
    "                name\n",
    "                from postgres_database.source_loading_info\n",
    "                where SOURCE_ID = {SOURCE_ID}\n",
    "                  and is_deleted is FALSE\n",
    "                  and to_reload is FALSE\n",
    "                  and load_datetime between '{SOURCE_LOAD_DATE_MIN}'::date and '{SOURCE_LOAD_DATE_MAX}'::date\n",
    "                group by 2, 3\n",
    "                order by 2;\"\"\"\n",
    "              \n",
    "    df_source_load_datetime_per_source = pd.read_sql(querry, cnx)\n",
    "    \n",
    "except Exception as e:\n",
    "        print(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove_input"
    ]
   },
   "outputs": [],
   "source": [
    "#Files to reload\n",
    "try:\n",
    "    querry = f\"\"\"\n",
    "                select source_id,\n",
    "                       to_reload,\n",
    "                       count(*)\n",
    "                from postgres_database.source_loading_info\n",
    "                where source_id = {SOURCE_ID}\n",
    "                group by 1, 2\n",
    "                \"\"\"\n",
    "              \n",
    "    df_reload = pd.read_sql(querry, cnx)\n",
    "    \n",
    "except Exception as e:\n",
    "        print(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove_input"
    ]
   },
   "outputs": [],
   "source": [
    "#SPN - Source Product Name\n",
    "try:\n",
    "    querry = f\"\"\"\n",
    "                select load_datetime,\n",
    "                    case\n",
    "                        when s_product_id is null then 's_product_id - empty'\n",
    "                        when s_product_id = 0 then 's_product_id = 0'\n",
    "                        when s_product_id > 0 then 's_product_id - ok'\n",
    "                        else 'Check'\n",
    "                        end as s_product_id,\n",
    "                    count(*) amount\n",
    "                from postgres_database.product_stock_info\n",
    "                where SOURCE_ID = {SOURCE_ID} and load_datetime between '{SOURCE_LOAD_DATE_MIN}' and '{SOURCE_LOAD_DATE_MAX}'\n",
    "                group by 1, 2\n",
    "                order by 1\n",
    "                \"\"\"\n",
    "    df_spn = pd.read_sql(querry, cnx)\n",
    "    \n",
    "except Exception as e:\n",
    "        print(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove_input"
    ]
   },
   "outputs": [],
   "source": [
    "# Old prices in price_product_info_latest\n",
    "try:\n",
    "    querry = f\"\"\"\n",
    "            select qty_min,\n",
    "                currency,\n",
    "                SOURCE_ID,\n",
    "                package_type_id,\n",
    "                region_id,\n",
    "                s_product_id,\n",
    "                symbol,\n",
    "                array_agg(product_id),\n",
    "                count(*)\n",
    "            from postgres_database.price_product_info_latest ppc\n",
    "                    join postgres_database.product pr on pr.id = ppc.product_id\n",
    "            where SOURCE_ID = {SOURCE_ID}\n",
    "\n",
    "            group by 1, 2, 3, 4, 5, 6, 7\n",
    "            having count(*) > 1;\n",
    "            \"\"\"\n",
    "    df_old_prices = pd.read_sql(querry,cnx)\n",
    "\n",
    "except Exception as e:\n",
    "        print(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove_input",
     "remove_output"
    ]
   },
   "outputs": [],
   "source": [
    "# price_product_info table validation\n",
    "\n",
    "# Lists for loaded data storage\n",
    "df_price_product_info_product_per_date_list = []\n",
    "df_price_product_info_packages_list = []\n",
    "df_price_product_info_max_min_list = []\n",
    "df_price_product_info_currency_list = []\n",
    "df_MRV_list = []\n",
    "\n",
    "# Loop which goes through load data intervals\n",
    "for i in range(len(load_dates_intervals_str) - 1): \n",
    "      \n",
    "    price_product_info_product_per_date = f\"\"\" select load_datetime,\n",
    "                                        count(product_id)\n",
    "                                        from postgres_database.price_product_info\n",
    "                                        where source_id = {SOURCE_ID}\n",
    "                                        and load_datetime > '{load_dates_intervals_str[i]}'::date AND load_datetime <= '{load_dates_intervals_str[i+1]}'::date\n",
    "                                        group by 1\n",
    "                                        order by 1\"\"\"\n",
    "\n",
    "    price_product_info_packages = f\"\"\"with price_product_info as(\n",
    "                                                select distinct package_type_id\n",
    "                                                from postgres_database.price_product_info\n",
    "                                                where source_id = {SOURCE_ID}\n",
    "                                                and load_datetime > '{load_dates_intervals_str[i]}'::date AND load_datetime <= '{load_dates_intervals_str[i+1]}'::date\n",
    "                                                ),\n",
    "\n",
    "                                    package_type as (\n",
    "                                        select id,\n",
    "                                                full_name\n",
    "                                        from postgres_database.package_type\n",
    "                                    ),\n",
    "\n",
    "                                    package_root as(\n",
    "                                        select ptr.id,\n",
    "                                            root_id,\n",
    "                                            full_name as full_name_root\n",
    "                                        from postgres_database_measure.package_type_root as ptr\n",
    "                                        left join package_type on package_type.id = ptr.root_id\n",
    "                                    )\n",
    "\n",
    "                                select distinct package_type_id,\n",
    "                                    full_name,\n",
    "                                    root_id,\n",
    "                                    full_name_root\n",
    "                                from price_product_info as pp\n",
    "                                left join package_type as pt on pt.id=pp.package_type_id\n",
    "                                left join package_root as pr on pr.id=pp.package_type_id; \"\"\"\n",
    "\n",
    "    price_product_info_max_min = f\"\"\"select max(price) as max_price\n",
    "                                    , min(price)  as min_price\n",
    "                                    , max(qty_min) as max_qty\n",
    "                                    , min(qty_min) as min_qty\n",
    "                                from postgres_database.price_product_info\n",
    "                                where source_id = {SOURCE_ID}\n",
    "                                and load_datetime > '{load_dates_intervals_str[i]}'::date AND load_datetime <= '{load_dates_intervals_str[i+1]}'::date;\"\"\"\n",
    "                            \n",
    "    price_product_info_currency = f\"\"\"select distinct region_id,\n",
    "                                            name as region_name,\n",
    "                                            currency\n",
    "                                from postgres_database.price_product_info as pp\n",
    "                                left join postgres_database.region on region.id = pp.region_id\n",
    "                                where source_id = {SOURCE_ID}\n",
    "                                and load_datetime > '{load_dates_intervals_str[i]}'::date AND load_datetime <= '{load_dates_intervals_str[i+1]}'::date;\"\"\"\n",
    "\n",
    "    # Minimum Row Value -> check if minimum value of product (minimum amount * product price) is not suspicious\n",
    "    MRV = f\"\"\"\n",
    "            with currency_rate as (\n",
    "                select\n",
    "                    currency_from,\n",
    "                    first(rate order by for_date desc) as latest_rate\n",
    "                from postgres_database.currency_rate\n",
    "                where currency_to = 'PLN'\n",
    "                group by 1\n",
    "                ),\n",
    "\n",
    "                price_product_infos as(\n",
    "                select pp.product_id,\n",
    "                    price,\n",
    "                    currency,\n",
    "                    load_datetime,\n",
    "                    qty_min,\n",
    "                    package_type_id,\n",
    "                    region_id,\n",
    "                    case when s_product_id is null then 0\n",
    "                        else s_product_id\n",
    "                            end as s_product_id,\n",
    "                    case when pp.currency = cr.currency_from then pp.price * cr.latest_rate\n",
    "                        else pp.price\n",
    "                            end as price_in_pln\n",
    "                from postgres_database.price_product_info as pp\n",
    "                left join currency_rate as cr on cr.currency_from = pp.currency\n",
    "                where source_id = {SOURCE_ID}\n",
    "                and load_datetime > '{load_dates_intervals_str[i]}'::date AND load_datetime <= '{load_dates_intervals_str[i+1]}'::date\n",
    "                and price < 1\n",
    "                ),\n",
    "\n",
    "                mop_per_date as(\n",
    "                        select product_id,\n",
    "                            package_type_id,\n",
    "                            region_id,\n",
    "                            s_product_id,\n",
    "                            max(load_datetime) as load_datetime,\n",
    "                            min(qty_min) as qty_min\n",
    "                        from price_product_infos\n",
    "                        group by 1,2,3,4\n",
    "                        ),\n",
    "\n",
    "                MRV as(\n",
    "                    select pp.product_id,\n",
    "                        pp.package_type_id,\n",
    "                        pp.region_id,\n",
    "                        pp.s_product_id,\n",
    "                        pp.load_datetime,\n",
    "                        pp.qty_min,\n",
    "                        price,\n",
    "                        currency,\n",
    "                        price_in_pln,\n",
    "                        (price_in_pln * mpd.qty_min)::float as MRV_pln\n",
    "                    from price_product_infos pp\n",
    "                    join mop_per_date as mpd on pp.product_id = mpd.product_id\n",
    "                            and mpd.load_datetime = pp.load_datetime\n",
    "                            and mpd.qty_min = pp.qty_min\n",
    "                            and mpd.package_type_id = pp.package_type_id\n",
    "                            and mpd.region_id = pp.region_id\n",
    "                            and mpd.s_product_id = pp.s_product_id\n",
    "                )\n",
    "\n",
    "            select product_id,\n",
    "                price,\n",
    "                currency,\n",
    "                price_in_pln,\n",
    "                qty_min,\n",
    "                MRV_pln,\n",
    "                load_datetime,\n",
    "                package_type_id,\n",
    "                region_id,\n",
    "                s_product_id\n",
    "            from MRV\n",
    "            where MRV_pln < 0.1; \"\"\"\n",
    "    \n",
    " # Loading data from database and adding it to the list                       \n",
    "    try:\n",
    "        df_price_product_info_product_per_date_load = pd.read_sql_query(price_product_info_product_per_date, cnx)\n",
    "        df_price_product_info_product_per_date_list.append(df_price_product_info_product_per_date_load)\n",
    "        \n",
    "        df_price_product_info_packages_load = pd.read_sql_query(price_product_info_packages, cnx)\n",
    "        df_price_product_info_packages_list.append(df_price_product_info_packages_load)\n",
    "               \n",
    "        df_price_product_info_max_min_load = pd.read_sql_query(price_product_info_max_min, cnx)\n",
    "        df_price_product_info_max_min_list.append(df_price_product_info_max_min_load) \n",
    "               \n",
    "        df_price_product_info_currency_load = pd.read_sql_query(price_product_info_currency, cnx)   \n",
    "        df_price_product_info_currency_list.append(df_price_product_info_currency_load)   \n",
    "        \n",
    "        df_MRV_load = pd.read_sql_query(MRV, cnx)\n",
    "        df_MRV_list.append(df_MRV_load)\n",
    "        \n",
    "        print(f\"Data loaded: {load_dates_intervals_str[i]} - {load_dates_intervals_str[i+1]}\")\n",
    "   \n",
    "    except Exception as e:\n",
    "            print(str(e))\n",
    "    \n",
    "# Concatenate data from list into one DataFrame\n",
    "df_price_product_info_product_per_date = pd.concat(df_price_product_info_product_per_date_list, ignore_index=True)\n",
    "df_price_product_info_packages = pd.concat(df_price_product_info_packages_list, ignore_index=True)\n",
    "df_price_product_info_max_min = pd.concat(df_price_product_info_max_min_list, ignore_index=True)\n",
    "df_price_product_info_currency = pd.concat(df_price_product_info_currency_list, ignore_index=True)\n",
    "df_MRV = pd.concat(df_MRV_list, ignore_index=True)\n",
    "\n",
    "# Duplicates removal\n",
    "df_price_product_info_packages.drop_duplicates(inplace=True)\n",
    "df_price_product_info_currency.drop_duplicates(inplace=True)\n",
    "\n",
    "# Dataframes details - info\n",
    "print(\"df_price_product_info_product_per_date:\", df_price_product_info_product_per_date.shape)\n",
    "print(\"df_price_product_info_packages:\", df_price_product_info_packages.shape)\n",
    "print(\"df_price_product_info_max_min:\", df_price_product_info_max_min.shape)\n",
    "print(\"df_price_product_info_currency:\", df_price_product_info_currency.shape)\n",
    "print(\"df_MRV:\", df_MRV.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove_input",
     "remove_output"
    ]
   },
   "outputs": [],
   "source": [
    "# product_stock_info table validation\n",
    "\n",
    "# Lists for loaded data storage\n",
    "df_product_stock_info_product_per_date_list = []\n",
    "df_product_stock_info_packages_list = []\n",
    "df_product_stock_info_max_min_list = []\n",
    "df_product_stock_info_region_list = []\n",
    "df_product_stock_info_higher_than_zero_list = []\n",
    "\n",
    "# Loop which goes through load data intervals\n",
    "for i in range(len(load_dates_intervals_str) - 1): \n",
    "\n",
    "    product_stock_info_product_per_date = f\"\"\" select load_datetime,\n",
    "                                                    count(product_id)\n",
    "                                        from postgres_database.product_stock_info\n",
    "                                        where source_id = {SOURCE_ID}\n",
    "                                        and load_datetime > '{load_dates_intervals_str[i]}'::date AND load_datetime <= '{load_dates_intervals_str[i+1]}'::date\n",
    "                                        group by 1\n",
    "                                        order by 1;\"\"\"\n",
    "\n",
    "    product_stock_info_packages = f\"\"\"with product_stock_info as(\n",
    "                                            select distinct package_type_id\n",
    "                                            from postgres_database.product_stock_info\n",
    "                                            where source_id = {SOURCE_ID}\n",
    "                                            and load_datetime > '{load_dates_intervals_str[i]}'::date AND load_datetime <= '{load_dates_intervals_str[i+1]}'::date\n",
    "                                    ),\n",
    "\n",
    "                                    package_type as (\n",
    "                                        select id,\n",
    "                                               full_name\n",
    "                                        from postgres_database.package_type\n",
    "                                    ),\n",
    "\n",
    "                                    package_root as(\n",
    "                                        select ptr.id,\n",
    "                                            root_id,\n",
    "                                            full_name as full_name_root\n",
    "                                        from postgres_database_measure.package_type_root as ptr\n",
    "                                        left join package_type on package_type.id = ptr.root_id\n",
    "                                    )\n",
    "\n",
    "                                select distinct package_type_id,\n",
    "                                    full_name,\n",
    "                                    root_id,\n",
    "                                    full_name_root\n",
    "                                from product_stock_info as pp\n",
    "                                left join package_type as pt on pt.id=pp.package_type_id\n",
    "                                left join package_root as pr on pr.id=pp.package_type_id;\"\"\"\n",
    "\n",
    "    product_stock_info_max_min = f\"\"\"select max(stock)  as max_stock,\n",
    "                                            min(stock)  as min_stock\n",
    "                                    from postgres_database.product_stock_info\n",
    "                                    where source_id = {SOURCE_ID}\n",
    "                                    and load_datetime > '{load_dates_intervals_str[i]}'::date AND load_datetime <= '{load_dates_intervals_str[i+1]}'::date;\"\"\"\n",
    "             \n",
    "    product_stock_info_region = f\"\"\" select distinct\n",
    "                                            region_id,\n",
    "                                            name as region_name\n",
    "                                from postgres_database.product_stock_info as ps\n",
    "                                left join postgres_database.region on region.id = ps.region_id\n",
    "                                where source_id = {SOURCE_ID}\n",
    "                                and load_datetime > '{load_dates_intervals_str[i]}'::date AND load_datetime <= '{load_dates_intervals_str[i+1]}'::date;\"\"\"\n",
    "                                \n",
    "    product_stock_info_higher_than_zero = f\"\"\"select load_datetime,\n",
    "                                                    case when stock = 0 then 'rowny zero'\n",
    "                                                            when stock > 0 then 'wiekszy od zera'\n",
    "                                                            else 'Podejrzany stock'\n",
    "                                                            end as stock_type,\n",
    "                                                    count(distinct product_id) as number_of_products\n",
    "                                                from postgres_database.product_stock_info as ps\n",
    "                                                left join postgres_database.region on region.id = ps.region_id\n",
    "                                                where source_id = {SOURCE_ID}\n",
    "                                                and load_datetime > '{load_dates_intervals_str[i]}'::date AND load_datetime <= '{load_dates_intervals_str[i+1]}'::date\n",
    "                                                group by 1,2;\"\"\"\n",
    "\n",
    "# Loading data from database and adding it to the list                        \n",
    "    try:\n",
    "        df_product_stock_info_product_per_date_load = pd.read_sql_query(product_stock_info_product_per_date, cnx)\n",
    "        df_product_stock_info_product_per_date_list.append(df_product_stock_info_product_per_date_load)\n",
    "        \n",
    "        df_product_stock_info_packages_load = pd.read_sql_query(product_stock_info_packages, cnx)\n",
    "        df_product_stock_info_packages_list.append(df_product_stock_info_packages_load)\n",
    "        \n",
    "        df_product_stock_info_max_min_load = pd.read_sql_query(product_stock_info_max_min, cnx)\n",
    "        df_product_stock_info_max_min_list.append(df_product_stock_info_max_min_load)\n",
    "        \n",
    "        df_product_stock_info_region_load = pd.read_sql_query(product_stock_info_region, cnx)\n",
    "        df_product_stock_info_region_list.append(df_product_stock_info_region_load)\n",
    "        \n",
    "        df_product_stock_info_higher_than_zero_load = pd.read_sql_query(product_stock_info_higher_than_zero, cnx)\n",
    "        df_product_stock_info_higher_than_zero_list.append(df_product_stock_info_higher_than_zero_load)\n",
    "        \n",
    "        print(f\"Data loaded: {load_dates_intervals_str[i]} - {load_dates_intervals_str[i+1]}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "            print(str(e))\n",
    "            \n",
    "# Concatenate data from list into one DataFrame\n",
    "df_product_stock_info_product_per_date = pd.concat(df_product_stock_info_product_per_date_list, ignore_index=True)\n",
    "df_product_stock_info_packages = pd.concat(df_product_stock_info_packages_list, ignore_index=True)\n",
    "df_product_stock_info_max_min = pd.concat(df_product_stock_info_max_min_list, ignore_index=True)\n",
    "df_product_stock_info_region = pd.concat(df_product_stock_info_region_list, ignore_index=True)\n",
    "df_product_stock_info_higher_than_zero = pd.concat(df_product_stock_info_higher_than_zero_list, ignore_index=True)\n",
    "\n",
    "# Duplicates removal\n",
    "df_product_stock_info_packages.drop_duplicates(inplace=True)\n",
    "df_product_stock_info_region.drop_duplicates(inplace=True)\n",
    "\n",
    "# Dataframes info\n",
    "print(\"df_product_stock_info_product_per_date:\", df_product_stock_info_product_per_date.shape)\n",
    "print(\"df_product_stock_info_packages:\", df_product_stock_info_packages.shape)\n",
    "print(\"df_product_stock_info_max_min:\", df_product_stock_info_max_min.shape)\n",
    "print(\"df_product_stock_info_region:\", df_product_stock_info_region.shape)\n",
    "print(\"df_product_stock_info_higher_than_zero:\", df_product_stock_info_higher_than_zero.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove_input",
     "remove_output"
    ]
   },
   "outputs": [],
   "source": [
    "# price_product_info_latest and product_stock_info_latest tabbles validation\n",
    "\n",
    "price_product_info_latest = f\"\"\" select *\n",
    "                                from postgres_database.price_product_info_latest\n",
    "                                where source_id = {SOURCE_ID}\n",
    "                                and load_datetime > '{SOURCE_LOAD_DATE_MIN}'::date\"\"\"\n",
    "\n",
    "product_stock_info_latest = f\"\"\" select *\n",
    "                                from postgres_database.product_stock_info_latest\n",
    "                                where source_id = {SOURCE_ID}\n",
    "                                and load_datetime > '{SOURCE_LOAD_DATE_MIN}'::date\"\"\"\n",
    "                     \n",
    "packages_price_product_info_latest = f\"\"\"with price_product_info as (\n",
    "                                                    select distinct package_type_id\n",
    "                                                    from postgres_database.price_product_info_latest\n",
    "                                                    where source_id = {SOURCE_ID}\n",
    "                                                    and load_datetime > '{SOURCE_LOAD_DATE_MIN}'::date\n",
    "                                                ),\n",
    "\n",
    "                                                package_type as (\n",
    "                                                    select id,\n",
    "                                                            full_name\n",
    "                                                    from postgres_database.package_type\n",
    "                                                ),\n",
    "\n",
    "                                                package_root as(\n",
    "                                                    select ptr.id,\n",
    "                                                        root_id,\n",
    "                                                        full_name as full_name_root\n",
    "                                                    from postgres_database_measure.package_type_root as ptr\n",
    "                                                    left join package_type on package_type.id = ptr.root_id\n",
    "                                                )\n",
    "\n",
    "                                            select distinct package_type_id,\n",
    "                                                full_name,\n",
    "                                                root_id,\n",
    "                                                full_name_root\n",
    "                                            from price_product_info as pp\n",
    "                                            left join package_type as pt on pt.id=pp.package_type_id\n",
    "                                            left join package_root as pr on pr.id=pp.package_type_id;\"\"\"\n",
    "\n",
    "packages_product_stock_info_latest = f\"\"\"with product_stock_info as (\n",
    "                                            select distinct package_type_id\n",
    "                                            from postgres_database.product_stock_info_latest\n",
    "                                            where source_id = {SOURCE_ID}\n",
    "                                            and load_datetime > '{SOURCE_LOAD_DATE_MIN}'::date\n",
    "                                            ),\n",
    "\n",
    "                                            package_type as (\n",
    "                                                select id,\n",
    "                                                        full_name\n",
    "                                                from postgres_database.package_type\n",
    "                                            ),\n",
    "\n",
    "                                            package_root as(\n",
    "                                                select ptr.id,\n",
    "                                                    root_id,\n",
    "                                                    full_name as full_name_root\n",
    "                                                from postgres_database_measure.package_type_root as ptr\n",
    "                                                left join package_type on package_type.id = ptr.root_id\n",
    "                                            )\n",
    "\n",
    "                                        select distinct package_type_id,\n",
    "                                            full_name,\n",
    "                                            root_id,\n",
    "                                            full_name_root\n",
    "                                        from product_stock_info as pp\n",
    "                                        left join package_type as pt on pt.id=pp.package_type_id\n",
    "                                        left join package_root as pr on pr.id=pp.package_type_id;\"\"\"\n",
    "                     \n",
    "try:\n",
    "    df_price_latest = pd.read_sql_query(price_product_info_latest, cnx)\n",
    "    df_stock_latest = pd.read_sql_query(product_stock_info_latest, cnx)\n",
    "    df_packages_price_product_info_latest = pd.read_sql_query(packages_price_product_info_latest, cnx)\n",
    "    df_packages_product_stock_info_latest = pd.read_sql_query(packages_price_product_info_latest, cnx)\n",
    "\n",
    "except Exception as e:\n",
    "        print(str(e))\n",
    "\n",
    "# DataFrames info        \n",
    "print(f\"price_latest: {df_price_latest.shape}\")\n",
    "print(f\"stock_latest: {df_stock_latest.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove_input"
    ]
   },
   "outputs": [],
   "source": [
    "# 10 random rows\n",
    "def random_rows_check(dataframe):\n",
    "    if dataframe.shape[0] == 0:\n",
    "        return 'No products to check'    \n",
    "    elif dataframe.shape[0] < 10:\n",
    "        return dataframe\n",
    "    else:\n",
    "        list_of_10_random_products = random.sample(range(0, dataframe.shape[0]), 10)\n",
    "        return dataframe.iloc[list_of_10_random_products]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove_input"
    ]
   },
   "outputs": [],
   "source": [
    "# Code needed for correct saving plots in html, needs to be run before creation of the plots\n",
    "import plotly.io\n",
    "plotly.io.renderers.default = \"notebook\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove_input"
    ]
   },
   "outputs": [],
   "source": [
    "# skonczylem tutaj\n",
    "print(\n",
    "f\"\"\"\n",
    "\n",
    "Source details: \n",
    "{SOURCE_ID} - {SOURCE_NAME} \n",
    "\n",
    "\"\"\")\n",
    "\n",
    "print(f\"\"\"\n",
    "      \n",
    "Following load dates of source were checked:\n",
    " \n",
    "from:\n",
    "{SOURCE_LOAD_DATE_MIN}\n",
    "\n",
    "to:\n",
    "{SOURCE_LOAD_DATE_MAX}\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "# check if correct column was chosen for manufacturer data\n",
    "print(\"\"\"Data about manufacturers was taken from following column:\\n\"\"\")\n",
    "display(manufacturer_column)\n",
    "\n",
    "# check if correct column was chosen for product name during the data load\n",
    "print(\"\"\"Data about products name was taken from following column:\\n\"\"\")\n",
    "display(prod_name_col)\n",
    "\n",
    "print(\"\"\"------------------------------------Price Product Info-------------------------------------\"\"\")\n",
    "\n",
    "# Product packages check -> check if suspicious packages werent loaded to database\n",
    "if df_price_product_info_packages.empty:\n",
    "    print('\\033[1mNo packages found for table price_product_info!\\033[0m')\n",
    "else:    \n",
    "    with pd.option_context('display.max_rows', None,\n",
    "                        'display.max_columns', None,\n",
    "                        'display.precision', 3,\n",
    "                        ):\n",
    "        print(\"Following packages found for table price_product_info:\")\n",
    "        display(df_price_product_info_packages)\n",
    "\n",
    "# Min/Max price check -> check if max price is not suspiciosly high and min price suspiciously low\n",
    "if  df_price_product_info_max_min.empty:\n",
    "    print(f\"No min/max price was foun in table: price_product_info\\n\")   \n",
    "else:\n",
    "    with pd.option_context('display.max_rows', None,\n",
    "                        'display.max_columns', None,\n",
    "                        'display.precision', 3,\n",
    "                        ):\n",
    "        print(f\"Following min/max prices were found for table: price_product_info, for following load dates:\\n{load_dates_intervals_str_string}\\n\")\n",
    "        display(df_price_product_info_max_min) \n",
    "\n",
    "# Currency/region check -> Check if correct currency was loaded for each region\n",
    "if  df_price_product_info_currency.empty:\n",
    "    print(f\"No currency/region was found in table price_product_info\\n\")   \n",
    "else:\n",
    "    with pd.option_context('display.max_rows', None,\n",
    "                        'display.max_columns', None,\n",
    "                        'display.precision', 3,\n",
    "                        ):\n",
    "        print(f\"I have found following currency/regions in table price_product_info:\\n\")\n",
    "        display(df_price_product_info_currency) \n",
    "\n",
    "print(\"\"\"------------------------------------Product Stock Info-------------------------------------\"\"\")\n",
    "\n",
    "# Product packages check -> check if suspicious packages werent loaded to database       \n",
    "if df_product_stock_info_packages.empty:\n",
    "    print('\\n\\033[1mNo packages found for table product_stock_info!\\033[0m\\n')\n",
    "else:    \n",
    "    with pd.option_context('display.max_rows', None,\n",
    "                        'display.max_columns', None,\n",
    "                        'display.precision', 3,\n",
    "                        ):\n",
    "        print(\"Following packages were found for table product_stock_info:\")\n",
    "        display(df_product_stock_info_packages)\n",
    "\n",
    "# Min/Max product stock check -> check if suspicious stock value was not loaded to database      \n",
    "if  df_product_stock_info_max_min.empty:\n",
    "    print(f\"No min/max value was found for stocks\\n\")   \n",
    "else:\n",
    "    with pd.option_context('display.max_rows', None,\n",
    "                        'display.max_columns', None,\n",
    "                        'display.precision', 3,\n",
    "                        ):\n",
    "        print(f\"Min/max stocks, for following load dates:\\n{load_dates_intervals_str_string}\\n\")\n",
    "        display(df_product_stock_info_max_min) \n",
    "\n",
    "# Region check        \n",
    "if  df_product_stock_info_region.empty:\n",
    "    print(f\"No region was found for table: product_stock_info\\n\")   \n",
    "else:\n",
    "    with pd.option_context('display.max_rows', None,\n",
    "                        'display.max_columns', None,\n",
    "                        'display.precision', 3,\n",
    "                        ):\n",
    "        print(f\"Following regions were found for table product_stock_info:\\n\")\n",
    "        display(df_product_stock_info_region) \n",
    "\n",
    "print(\"\"\"-------------------------------------------------------------------------------------\"\"\")\n",
    "\n",
    "# Old prices load check -> 2 prices for 1 product (in following table there should be only latest price) -> table price_product_info_latest\n",
    "if df_old_prices.empty:\n",
    "    print(f\"No old prices were found in table: price_product_info_latest\\n\")\n",
    "else:\n",
    "    print(f\"There were found probable doubled loads in table price_product_info_latest \\n there are 2 prices for 1 product due to different manufactures which are not synonimized\")\n",
    "    display(df_old_prices)\n",
    "\n",
    "# 10 random products with suspicious MRV (Minimum Row Value) which need to be checked\n",
    "print(f\"\\nNumber of products with suspicious MRV: {df_MRV.shape[0]}\")\n",
    "print('List of 10 products with suspicious MRV which needs to be checked:')  \n",
    "display(random_rows_check(df_MRV))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove_input"
    ]
   },
   "outputs": [],
   "source": [
    "# List of unique workflow names for function suspicious_data -> number of rows in raw files\n",
    "list_of_suspicious_workflow_names = []\n",
    "for i in df_row_count.WORKFLOW_NAME:\n",
    "    if i not in list_of_suspicious_workflow_names:\n",
    "        list_of_suspicious_workflow_names.append(i)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove_input"
    ]
   },
   "outputs": [],
   "source": [
    "# Comparison of table source_loading_info_init with number of rows in raw files\n",
    "for name in list_of_suspicious_workflow_names:\n",
    "    print(f\"\"\"Checking table source_loading_info_init and number of raw files rows (row_count) for \\033[1mworkflow: {i}\\033[0m\"\"\")\n",
    "    suspicious_data(df_row_count.loc[df_row_count['WORKFLOW_NAME']==f'{name}'])\n",
    "\n",
    "\n",
    "figure1 = px.line(df_row_count, \n",
    "              x=\"load_datetime\", \n",
    "              y=\"amount\", \n",
    "              color='WORKFLOW_NAME', \n",
    "              markers=True,\n",
    "                    full_name = 'Sum of raw files rows per week and workflow',\n",
    "                    labels={\n",
    "                     \"amount\": \"Number of rows\",\n",
    "                     \"WORKFLOW_NAME\": \"Workflow name\",\n",
    "                     \"weeks\": \"week-month-year\"\n",
    "                 },\n",
    "              width=1500, \n",
    "              height=600)\n",
    "figure1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove_input"
    ]
   },
   "outputs": [],
   "source": [
    "# Prices load check\n",
    "print(f\"Number of prices load per day check\")\n",
    "df_price_product_info_product_per_date_suspicious = df_price_product_info_product_per_date.rename(columns = {'load_datetime':'load_date', 'count':'amount'})\n",
    "suspicious_data(df_price_product_info_product_per_date_suspicious)\n",
    "\n",
    "df_price_product_info_product_per_date = df_price_product_info_product_per_date.rename(columns = {'load_datetime':'load_date', 'count':'number_of_loaded_prices'})\n",
    "\n",
    "figure2 = px.line(df_price_product_info_product_per_date, \n",
    "              x=\"load_date\", \n",
    "              y=\"number_of_loaded_prices\", \n",
    "              full_name='Number of loads per day for prices',\n",
    "              markers=True, \n",
    "              width=1500, \n",
    "              height=600,\n",
    "              )\n",
    "\n",
    "figure2.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove_input"
    ]
   },
   "outputs": [],
   "source": [
    "# SPN check\n",
    "print(f\"SPN check\")\n",
    "suspicious_data(df_spn)\n",
    "\n",
    "figure3 = px.line(df_spn.sort_values(by='load_datetime'), \n",
    "              x=\"load_datetime\", \n",
    "              y=\"amount\", \n",
    "              color='s_product_id', \n",
    "              markers=True,\n",
    "                    full_name = f'Quantity and type of SPN for {SOURCE_NAME}',\n",
    "                    labels={\n",
    "                     \"amount\": \"Number of rows\",\n",
    "                     \"s_product_id\": \"SPN type\"\n",
    "                 },\n",
    "              width=1500, \n",
    "              height=600)\n",
    "figure3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove_input"
    ]
   },
   "outputs": [],
   "source": [
    "# Stock load\n",
    "df_product_stock_info_product_per_date = df_product_stock_info_product_per_date.rename(columns = {'load_datetime':'load_date', 'count':'number_of_loaded_stocks'})\n",
    "\n",
    "figure4 = px.line(df_product_stock_info_product_per_date, \n",
    "              x=\"Load_date\", \n",
    "              y=\"Number_of_loaded_stocks\", \n",
    "              full_name='Number_of_loaded_stocks_per_date', \n",
    "              markers=True, \n",
    "              width=1500, \n",
    "              height=600)\n",
    "\n",
    "figure4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove_input"
    ]
   },
   "outputs": [],
   "source": [
    "# Amount and type of stock (stock>0 or stock=0) loaded\n",
    "figure5 = px.line(df_product_stock_info_higher_than_zero, \n",
    "              x=\"load_datetime\", \n",
    "              y=\"number_of_products\", \n",
    "              color='stock_type', \n",
    "              full_name='Quantity and stock type loaded per day',\n",
    "              markers=True, \n",
    "              width=1500, \n",
    "              height=600)\n",
    "\n",
    "figure5.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove_input"
    ]
   },
   "outputs": [],
   "source": [
    "# Number of loaded prices per date\n",
    "number_of_products_per_load = df_price_latest[['load_datetime', 'product_id']].groupby(by='load_datetime', as_index=False).count()\n",
    "number_of_products_per_load_figure = number_of_products_per_load.rename(columns = {'load_datetime':'load_date', 'product_id':'number_of_loaded_prices'})\n",
    "\n",
    "figure6 = px.line(number_of_products_per_load_figure, \n",
    "              x=\"load_date\", \n",
    "              y=\"number_of_loaded_prices\", \n",
    "              full_name='Number of loaded prices per date, table: price_product_info_latest', \n",
    "              markers=True, \n",
    "              width=1500, \n",
    "              height=600)\n",
    "\n",
    "figure6.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove_input"
    ]
   },
   "outputs": [],
   "source": [
    "# Number of zero SPNs loaded\n",
    "number_of_zero_spn = df_price_latest[df_price_latest['s_product_id'] == 0][['load_datetime', 's_product_id']].groupby(by='load_datetime', as_index=False).count()\n",
    "\n",
    "figure7 = px.line(number_of_zero_spn, \n",
    "              x=\"load_datetime\", \n",
    "              y=\"s_product_id\", \n",
    "              full_name='Number of loads of zero SPNs, table: price_product_info_latest', \n",
    "              markers=True, \n",
    "              )\n",
    "\n",
    "figure7.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove_input"
    ]
   },
   "outputs": [],
   "source": [
    "print(\"Number of stocks loaded, based on table product_stock_info_latest\\n\")\n",
    "\n",
    "number_of_products_per_load = df_stock_latest[['load_datetime', 'product_id']].groupby(by='load_datetime', as_index=False).count()\n",
    "number_of_products_per_load_figure = number_of_products_per_load.rename(columns = {'load_datetime':'load_date', 'product_id':'number of loaded stocks'})\n",
    "\n",
    "figure8 = px.line(number_of_products_per_load_figure, \n",
    "              x=\"load_date\", \n",
    "              y=\"number of loaded stocks\", \n",
    "              full_name='Number of stocks loaded per date, table product_stock_info_latest', \n",
    "              markers=True, \n",
    "              width=1500, \n",
    "              height=600)\n",
    "\n",
    "figure8.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove_input"
    ]
   },
   "outputs": [],
   "source": [
    "# Number of zero SPNs from product_stock_info_latest\n",
    "number_of_zero_spn_stock_curr = df_stock_latest[df_stock_latest['s_product_id'] == 0][['load_datetime', 's_product_id']].groupby(by='load_datetime', as_index=False).count()\n",
    "\n",
    "figure9 = px.line(number_of_zero_spn_stock_curr, \n",
    "              x=\"load_datetime\", \n",
    "              y=\"s_product_id\", \n",
    "              full_name='Number of zero SPNs from product_stock_info_latest', \n",
    "              markers=True, \n",
    "              )\n",
    "\n",
    "figure9.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove_input"
    ]
   },
   "outputs": [],
   "source": [
    "print(\"Check of table product_stock_info_latest\\n\")\n",
    "try:\n",
    "    if df_stock_latest.empty:\n",
    "        print(\"Table product_stock_info_latest is empty.\")\n",
    "    else:       \n",
    "        # product_stock_info_latest stats - min/max stock, regions, packages\n",
    "        stock_max_stock_latest = int(df_stock_latest.stock.max())\n",
    "        stock_min_stock_latest = int(df_stock_latest.stock.min())\n",
    "        \n",
    "        region_stock_latest = df_stock_latest.loc[:,['region_id']]\n",
    "        region_stock_latest.drop_duplicates(inplace=True)\n",
    "        region_stock_latest.sort_values(by='region_id', inplace=True)\n",
    "        \n",
    "        print(\"Regions found in table product_stock_info_latest:\")\n",
    "        display(region_stock_latest)\n",
    "        \n",
    "        print(\"Following packages were found for table product_stock_info_latest:\")\n",
    "        display(df_packages_product_stock_info_latest)\n",
    "        \n",
    "        print(\"\\n\\nMax stock found in product_stock_info_latest:\", stock_max_stock_latest)\n",
    "        print(\"Min stock found in product_stock_info_latest:\", stock_min_stock_latest)\n",
    "\n",
    "except Exception as e:\n",
    "    print(str(e))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Check of table price_product_info_latest\\n\")\n",
    "try:\n",
    "    if df_price_latest.empty:\n",
    "        print(\"Table price_product_info_latest is empty.\")        \n",
    "    else:  \n",
    "        max_price_price_latest = float(df_price_latest.price.max())\n",
    "        min_price_price_latest = float(df_price_latest.price.min())\n",
    "\n",
    "        currency_region_price_latest = df_price_latest.loc[:, ['region_id', 'currency']]\n",
    "        currency_region_price_latest.drop_duplicates(inplace=True)\n",
    "        currency_region_price_latest.sort_values(by='region_id', inplace=True)\n",
    "\n",
    "        print(\"Regions and currencies found for table: price_product_info_latest:\")\n",
    "        display(currency_region_price_latest)\n",
    "        \n",
    "        print(\"Packages found for: price_product_info_latest:\")\n",
    "        display(df_packages_price_product_info_latest)\n",
    "        \n",
    "        print(\"\\n\\nMax price found in table: price_product_info_latest:\", max_price_price_latest)\n",
    "        print(\"Min price found in table: price_product_info_latest:{:.10f}\".format(min_price_price_latest))\n",
    "\n",
    "except Exception as e:\n",
    "    print(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove_input"
    ]
   },
   "outputs": [],
   "source": [
    "# Number of suspicious stocks \n",
    "print('Number of suspicious stocks loaded:\\n')\n",
    "try:\n",
    "    df_product_stock_info_product_per_date_suspicious = df_product_stock_info_product_per_date.rename(columns = {'load_datetime':'load_date', 'ilosc_zaladowanych_stockow':'amount'})\n",
    "    suspicious_data(df_product_stock_info_product_per_date_suspicious)\n",
    "    display(suspicious_data)\n",
    "\n",
    "except Exception as e:\n",
    "    print(str(e))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "remove_input",
     "remove_output"
    ]
   },
   "source": [
    "## Saving report to html file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove_input",
     "remove_output"
    ]
   },
   "outputs": [],
   "source": [
    "from traitlets.config import Config\n",
    "import nbformat as nbf\n",
    "from nbconvert.exporters import HTMLExporter\n",
    "from nbconvert.preprocessors import TagRemovePreprocessor\n",
    "\n",
    "# Setup config\n",
    "c = Config()\n",
    "\n",
    "# Configure tag removal\n",
    "c.TagRemovePreprocessor.remove_cell_tags = (\"remove_cell\",)\n",
    "c.TagRemovePreprocessor.remove_all_outputs_tags = ('remove_output',)\n",
    "c.TagRemovePreprocessor.remove_input_tags = ('remove_input',)\n",
    "c.TagRemovePreprocessor.enabled = True\n",
    "\n",
    "# Configure and run out exporter\n",
    "c.HTMLExporter.preprocessors = [\"nbconvert.preprocessors.TagRemovePreprocessor\"]\n",
    "\n",
    "exporter = HTMLExporter(config=c)\n",
    "exporter.register_preprocessor(TagRemovePreprocessor(config=c),True)\n",
    "\n",
    "# Configure and run our exporter - returns a tuple - first element with html,\n",
    "# second with notebook metadata\n",
    "output = HTMLExporter(config=c).from_filename(\"Source_validation.ipynb\")\n",
    "\n",
    "# Write to output html file\n",
    "with open(\"source_validation_full.html\",  \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(output[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9b4d75ac280b6c7c3aa43866cb82dc88915409b55fec83a093dd0284cb58708e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
